<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Image Generator: Application and Implementation of StyleGAN - Yuzi Liang | University of Science and Technology of China</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Yuzi Liang | University of Science and Technology of China"><meta name="msapplication-TileImage" content="/img/favicon2.ico"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Yuzi Liang | University of Science and Technology of China"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Image Generator: Application and Implementation of StyleGAN 一 项目简介 二 项目目标 1.项目目标 2.基本原理与模型 2.1 极大似然估计 2.2 GAN的基本原理 2.3 StyleGAN对于人脸生成的优化     三 项目具体实现 1.爬虫 1.1 Pixiv 1.1.1 fetInfo.py 1.1.2 findPID.py"><meta property="og:type" content="blog"><meta property="og:title" content="Image Generator: Application and Implementation of StyleGAN"><meta property="og:url" content="http://example.com/2021/08/28/Image-Generator-Application-and-Implementation-of-StyleGAN/"><meta property="og:site_name" content="Yuzi Liang | University of Science and Technology of China"><meta property="og:description" content="Image Generator: Application and Implementation of StyleGAN 一 项目简介 二 项目目标 1.项目目标 2.基本原理与模型 2.1 极大似然估计 2.2 GAN的基本原理 2.3 StyleGAN对于人脸生成的优化     三 项目具体实现 1.爬虫 1.1 Pixiv 1.1.1 fetInfo.py 1.1.2 findPID.py"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://example.com/images/1cv.png"><meta property="og:image" content="http://example.com/images/2cv.png"><meta property="og:image" content="http://example.com/images/3cv.png"><meta property="og:image" content="http://example.com/images/4cv.png"><meta property="og:image" content="http://example.com/images/5cv.png"><meta property="og:image" content="http://example.com/images/pixiv.png"><meta property="og:image" content="http://example.com/images/onedrive.png"><meta property="og:image" content="http://example.com/images/face.png"><meta property="og:image" content="http://example.com/images/gan1.jpg"><meta property="og:image" content="http://example.com/images/gan2.jpg"><meta property="article:published_time" content="2021-08-28T07:59:55.000Z"><meta property="article:modified_time" content="2023-09-25T21:25:46.773Z"><meta property="article:author" content="Yuzi Liang"><meta property="article:tag" content="Machine Learning"><meta property="article:tag" content="Web Crawler"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/images/1cv.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com/2021/08/28/Image-Generator-Application-and-Implementation-of-StyleGAN/"},"headline":"Yuzi Liang | University of Science and Technology of China","image":["http://example.com/images/1cv.png","http://example.com/images/2cv.png","http://example.com/images/3cv.png","http://example.com/images/4cv.png","http://example.com/images/5cv.png","http://example.com/images/pixiv.png","http://example.com/images/onedrive.png","http://example.com/images/face.png","http://example.com/images/gan1.jpg","http://example.com/images/gan2.jpg"],"datePublished":"2021-08-28T07:59:55.000Z","dateModified":"2023-09-25T21:25:46.773Z","author":{"@type":"Person","name":"Yuzi Liang"},"description":"Image Generator: Application and Implementation of StyleGAN 一 项目简介 二 项目目标 1.项目目标 2.基本原理与模型 2.1 极大似然估计 2.2 GAN的基本原理 2.3 StyleGAN对于人脸生成的优化     三 项目具体实现 1.爬虫 1.1 Pixiv 1.1.1 fetInfo.py 1.1.2 findPID.py"}</script><link rel="canonical" href="http://example.com/2021/08/28/Image-Generator-Application-and-Implementation-of-StyleGAN/"><link rel="icon" href="/img/favicon2.ico"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/ustc_logo.jpg" alt="Yuzi Liang | University of Science and Technology of China" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-08-28T07:59:55.000Z" title="8/28/2021, 12:59:55 AM">2021-08-28</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-09-25T21:25:46.773Z" title="9/25/2023, 2:25:46 PM">2023-09-25</time></span><span class="level-item"><a class="link-muted" href="/categories/Project-Summary/">Project Summary</a></span><span class="level-item">36 minutes read (About 5409 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">Image Generator: Application and Implementation of StyleGAN</h1><div class="content"><!-- toc -->
<ul>
<li><a href="#image-generator-application-and-implementation-of-stylegan">Image Generator: Application and Implementation of StyleGAN</a><ul>
<li><a href="#一-项目简介">一 项目简介</a></li>
<li><a href="#二-项目目标">二 项目目标</a><ul>
<li><a href="#1项目目标"><strong>1.项目目标</strong></a></li>
<li><a href="#2基本原理与模型"><strong>2.基本原理与模型</strong></a><ul>
<li><a href="#21-极大似然估计">2.1 极大似然估计</a></li>
<li><a href="#22-gan的基本原理">2.2 GAN的基本原理</a></li>
<li><a href="#23-stylegan对于人脸生成的优化">2.3 StyleGAN对于人脸生成的优化</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#三-项目具体实现">三 项目具体实现</a><ul>
<li><a href="#1爬虫">1.爬虫</a><ul>
<li><a href="#11-pixiv">1.1 Pixiv</a><ul>
<li><a href="#111-fetinfopy">1.1.1 fetInfo.py</a></li>
<li><a href="#112-findpidpy">1.1.2 findPID.py</a></li>
<li><a href="#113-findfollowpy">1.1.3 findFollow.py</a></li>
<li><a href="#114-mainpy">1.1.4 main.py</a></li>
</ul>
</li>
<li><a href="#12-konachan">1.2 Konachan</a></li>
</ul>
</li>
<li><a href="#2人脸提取">2.人脸提取</a></li>
<li><a href="#3部署环境运行代码">3.部署环境运行代码</a><ul>
<li><a href="#第一台电脑上的环境部署">第一台电脑上的环境部署</a></li>
</ul>
</li>
<li><a href="#第二台电脑上的环境部署"><strong>第二台电脑上的环境部署</strong></a></li>
</ul>
</li>
<li><a href="#四-结果展示">四 结果展示</a></li>
<li><a href="#五-关于gan的进一步讨论">五 关于GAN的进一步讨论</a><ul>
<li><a href="#gan优点">GAN优点</a></li>
<li><a href="#gan缺点">GAN缺点</a></li>
<li><a href="#gan应用">GAN应用</a></li>
<li><a href="#gan引起的担忧危害">GAN引起的担忧（危害）</a></li>
</ul>
</li>
<li><a href="#六-关于本项目的总结">六 关于本项目的总结</a></li>
</ul>
</li>
</ul>
<!-- tocstop -->
<h1><span id="image-generator-application-and-implementation-of-stylegan">Image Generator: Application and Implementation of StyleGAN</span></h1><h2><span id="一-项目简介">一 项目简介</span></h2><p>​        深度学习是近十年来人工智能领域取得的最重要的突破之一。它在语音识别、自然语言处理、计算机视觉、图像与视频分析、多媒体等诸多领域都取得了巨大成功。而其中，生成式对抗网络（GAN,Generative Adversarial Networks）这一深度学习模型是近年来复杂分布上无监督学习最具前景的方法之一，广泛应用于图像生成和图像识别的领域中，如神经风格迁移、Google公司开发的Deep Dream算法和变分自编码器。</p>
<p>​        最近在动漫绘画领域当中，也开始有人尝试用机器学习来制作2D动漫图像，从而代替传统的手绘和三渲二这些较为耗人力、制作周期长的方法。cinnamon AI开始提供动漫自动着色功能，可以进行一定的补齐线稿缺线的预处理以及自动上色的功能，将对单元图像进行着色所需时间缩短至1/10，并且将成本降低了50%以上，一定程度上减少画师的工作量，提高动漫创作者的生产力；ATD-12K是一个大规模的动画的三元组帧间数据集，可以在两幅图直接自动生成图像插帧，从而在保证动画质量的基础上大大减少了动画制作者的成本和制作时间。虽然现在这些技术还没有普遍应用在动画中，但可以肯定随着机器学习模型进一步的完善和训练，深度学习生成动漫图像来替代人工手作图已是必然趋势，之后的画师不必再花大量的时间去设计人物，也不需要花大量的精力为了动漫的流畅度去一帧帧的画图，只需一些简单的线稿，一些动画镜头的关键帧，剩下的就只需要交给深度学习模型去完成这部动画。当绘画和动画的工作不再是主要制作成本和时间后，不仅仅会推动动漫领域的发展，电影，游戏以及更多需要可视化图像的领域都能被加速推动发展。</p>
<p>​        本文我们将采用StyleGAN深度学习模型进行训练，达到通过随机种子的输入，得到随机动漫人物头像图片的结果。在该模型已有参考代码的情况下，其关键点就在于配置好Python环境，制作庞大且合适的训练集以及调整初始参数。       </p>
<h2><span id="二-项目目标">二 项目目标</span></h2><h3><span id="1项目目标"><strong>1.项目目标</strong></span></h3><p>​      制作合适的训练集，利用StyleGAN深度学习模型训练，可以随机生成动漫人物头像图片。</p>
<h3><span id="2基本原理与模型"><strong>2.基本原理与模型</strong></span></h3><h4><span id="21-极大似然估计">2.1 极大似然估计</span></h4><p>​        在理解GAN生成图像原理前，我们先从极大似然估计说起。我们用$P(x,\theta)$表示每个样本x分布的概率，其中$\theta$表示该分布的参数。那么极大似然估计需要解决的就是已知一个数据分布$P_{data}(x)$，再给定一个有参数$\theta$定义的数据分布$P_{G}(x,\theta)$，我们希望求得参数$\theta$使得$P_{G}(x,\theta)$尽可能接近$P_{data}(x)$。那么在图像生成中，我们导入的训练集的图片，其每个像素点每个通道的灰度值的集合就相当于一个数据分布$P_{data}(x)$，我们要做的就是寻找一个$P_{G}(x,\theta)$去接近这一分布，这样当我们再随机代入参数$\theta$值时，就相当于生成了一个和数据集图片类似但不重复的新图片。</p>
<p>​        那么重点就在于怎样求得参数$\theta$，理论上需要三步：</p>
<p>​        1.从$P_{data}(x)$采样m个样本{$x^1,x^2,…,x^m$}</p>
<p>​        2.计算采样样本的似然函数 $L=\prod_{i=1}^m P_G(x^i;\theta)$</p>
<p>​        3.计算使得似然函数$L$最大的参数$\theta$：$\theta^{*}={\underset{\theta}{\operatorname{arg\,max}}}\ L={\underset{\theta}{\operatorname{arg\,max}}}\prod_{i=1}^m P_G(x^i;\theta)$</p>
<p>​        我们继续上式的计算：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\theta^*&={\underset{\theta}{\operatorname{arg\,max}}}\ L \\
&\approx {\underset{\theta}{\operatorname{arg\,max}}}\ E_{x\backsim P_{data}}[\operatorname{log}P_G(x;\theta)]\\
&={\underset{\theta}{\operatorname{arg\,max}}}\ \int_x P_{data}(x)\operatorname{log}P_G(x;\theta)dx-\int_x P_{data}(x)\operatorname{log}P_{data}(x)dx\\
&={\underset{\theta}{\operatorname{arg\,min}}}\ KL(P_{data}(x)||P_G(x;\theta))
\end{aligned}</script><p>​       其中用到了KL散度：KL(P||Q)，用于衡量P，Q这两个概率分布差异的方式：</p>
<script type="math/tex; mode=display">
KL(P||Q)=\int_x p(x)(\operatorname{log}p(x)-\operatorname{log}q(x))</script><p>​       即我们找到一个$\theta$使得$P_G(x;\theta)$与目标分布$P_{data}(x)$的KL散度尽可能低，即可确定参数$\theta$。</p>
<h4><span id="22-gan的基本原理">2.2 GAN的基本原理</span></h4><p>​       知道极大似然估计对于图像生成的帮助后，GAN本质上就是在做极大似然估计的事情，我们希望可以用某一种具体的分布形式$P_G(x;\theta)$尽可能逼真地表达分布$P_{data}(x)$，这样我们就相当于得到了$P_{data}(x)$，并据此分布$P_G(x;\theta)$采样，即做生成任务。由于神经网络具有强大拟合能力，我们设计一个神经网络G来得到更普适的$P_G(x;\theta)$，大致的结构图如下：</p>
<center class="full">
<img src="/images/1cv.png" width="80%">
</center>


<p>​       我们先选取一个简单的先验分布$P_{prior}$,并从该先验分布中采样$z$作为输入，输入到神经网络$G$，得$G(z)=x$生成图像$x$。我们通过这种方式构建了生成分布$P_{G}{x;\theta}$。此时该分布主要由神经网络$G$决定，参数$\theta$由网络参数定义，我们可以通过输入$z$来在该分布上采样$x$。类似极大似然估计，我们通过比较两个分布样本的差异设计loss来调节优化神经网络$G$的参数$\theta$，从而实现将分布$P_G$向$P_{data}$拉近，达到用$P_G$拟合表达$P_{data}$的效果。不过，直接计算$\theta$值是不可能的，这时候我们就需要用到GAN来帮助我们拟合。</p>
<p>​        GAN由生成器G和判别器D组成，上一段其实就是生成器G所做的工作，即G就是一个函数，输入$z\backsim P_{prior}$，输出$x\backsim P_G$。而判别器D的作用就是用来评估$P_G(x,\theta)$和$P_{data}(x)$之间的差异，本质上也是一个函数，输入$x\backsim P_G$,输出一个数值来衡量差异。GAN最后的目标用符号化语言表示就是：</p>
<script type="math/tex; mode=display">
G^*=\operatorname{arg}\ {\underset{G}{\operatorname{min}}}\ {\underset{D}{\operatorname{max}}}\ V(G,D)</script><p>我们的目标是得到使得式子${\underset{D}{\operatorname{max}}}\ V(G,D)$最小的生成器$G^*$。</p>
<p>​       关于$V$:</p>
<script type="math/tex; mode=display">
V(G,D)=E_{x\backsim P_{data}}[\operatorname{log}D(x)]+E_{x\backsim P_{G}}[1-\operatorname{log}D(x)]</script><p>​       那么我们该如何优化获得$G^*$呢？这里可以通过梯度下降法来实现：</p>
<script type="math/tex; mode=display">
\theta_G \rightarrow \theta_G -\eta \frac{\partial L(G)}{\partial \theta_G}</script><p>其中$ L(G) = {\underset{D}{\operatorname{max}}}\ V(G,D) = V^\star(G,D^\star) $ .</p>
<p>我们将D看为二分类器，那么确定D，就可以使用梯度下降来优化D的最终参数。我们可以将 $ {\underset{D}{\operatorname{max}}}\ V(G,D) $从期望值计算改写为样本计算（近似估计）：</p>
<script type="math/tex; mode=display">
\tilde{V}=\frac{1}{m}\sum_{i=1}^{m}\operatorname{log}D(x^i)+\frac{1}{m}\sum_{i=1}^{m}\operatorname{log}(1-D(\tilde{x^i}))</script><p>则最终GAN的算法流程为：</p>
<p>1.初始化参数$\theta_D$和$\theta_G$</p>
<p>2.学习优化判别器D：</p>
<p>​    $\cdot$ 从$P_{data}(x)$采样{$x^1,x^2,…,x^m$}</p>
<p>​    $\cdot$从$P_{prior}(z)$采样{$z^1,z^2,…,z^m$}</p>
<p>​    $\cdot$通过生成器$\tilde{x^i}=G(z^i)$获得生成样本{$\tilde{x^1},\tilde{x^2},…,\tilde{x^m}$}</p>
<p>​    $\cdot$梯度下降更新$\theta_D$来最大化$\tilde{V}=\frac{1}{m}\sum_{i=1}^{m}\operatorname{log}D(x^i)+\frac{1}{m}\sum_{i=1}^{m}\operatorname{log}(1-D(\tilde{x^i}))$</p>
<p>3.学习优化生成器G：</p>
<p>​    $\cdot$再从$P_{prior}(z)$采样另一组{$z^1,z^2,…,z^m$}</p>
<p>​    $\cdot$梯度下降更新$\theta_G$来最小化$\tilde{V}=\frac{1}{m}\sum_{i=1}^{m}\operatorname{log}D(x^i)+\frac{1}{m}\sum_{i=1}^{m}\operatorname{log}(1-D(G(z^i)))$</p>
<h4><span id="23-stylegan对于人脸生成的优化">2.3 StyleGAN对于人脸生成的优化</span></h4><p>Paper:<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1812.04948">[1812.04948] A Style-Based Generator Architecture for Generative Adversarial Networks (arxiv.org)</a></p>
<p>​        StyleGAN，提出了一个新的 generator architecture，号称能够控制所生成图像的高层级属性(high-level attributes)，如发型、雀斑等，并且生成的图像在一些评价标准上得分更好，这也是我们最终选择这个模型的原因。其相对于传统GAN有以下改进：</p>
<p>（1）Style-based generator</p>
<p>​        不同于常见的直接把 latent code 输入给 generator 的输入层的做法，该模型摒弃了输入层， 转而添加了一个非线性映射网络：$f:Z\rightarrow W$，如下图：</p>
<center class="full">
<img src="/images/2cv.png" width="80%">
</center>


<p>图中，<code>z</code>和<code>w</code>的维度都是512维，<code>A</code>是一个仿射变换(Affine transform)，<code>B</code>是每个channel的高斯噪声的系数，而<code>AdaIN</code>则是：</p>
<center class="full">
<img src="/images/3cv.png" width="60%">
</center>


<p>图中，$y(s,i)$和$y(b,i)$则是<code>w</code>经过<code>A</code>变换之后得到的$y=(y_s,y_b),(y(s,i),y(b,i))$对的个数与每一层feature map的channel数相同。</p>
<p>（2）Style mixing</p>
<p>​       为进一步促使这些<code>style</code>来局部化其控制效果，作者又采用了<code>mixing regularization</code>。style-based generator的8层卷积的非线性变换中，提前计算两个图像的变换结果$w_1、w_2$，然后在生成过程中随机取$w_1$或者$w_2$的值进行操作。如下图：</p>
<center class="full">
<img src="/images/4cv.png" width="80%">
</center>


<p>（3）Stochastic variation</p>
<p>​       人有很多随机属性，例如头发、胡须、雀斑等，所以一个好的generator自然也要能够实现stochastic variation。而该论文作者认为，传统的generator的输入就只有输入层，所以generator自身必须寻找一种生成伪随机数的方式，而这会消耗网络的<code>capacity</code>，并且很难隐藏生成的 信号的周期性。而这时，该模型的高斯噪声输入<code>B</code>就派上了用场了。如下图：</p>
<center class="full">
<img src="/images/5cv.png" width="80%">
</center>



<h2><span id="三-项目具体实现">三 项目具体实现</span></h2><p>主要分为三步：爬取图片、截取人脸部分、部署环境运行代码。</p>
<h3><span id="1爬虫">1.爬虫</span></h3><h4><span id="11-pixiv">1.1 Pixiv</span></h4><p><a target="_blank" rel="noopener" href="https://www.pixiv.net是一个插画分享网站,不过大部分情况下直接搜索tag只能得到按照时间排序的结果,结果通常参差不齐,很难看到高质量的作品">https://www.pixiv.net是一个插画分享网站,不过大部分情况下直接搜索tag只能得到按照时间排序的结果,结果通常参差不齐,很难看到高质量的作品</a>:</p>
<center class="full">
<img src="/images/pixiv.png" width="50%">
</center>



<p>按照热度排序还需要付费会员,很不划算,所以我写了多种爬虫策略.最终项目包含四个程序:findPID.py,findFollow.py,getInfo.py,main.py.</p>
<p>包含的功能包括爬取指定id的插画,按照作者id爬取作品,爬取日榜,周榜,月榜,爬取公开关注画师的作品,爬取悄悄关注画师的作品等.当然这个关注的画师和程序中用到的cookies有关,有需要可以替换成自己的cookies.</p>
<h5><span id="111-fetinfopy">1.1.1 fetInfo.py</span></h5><p>一一介绍一下包含的函数功能</p>
<p><em>GetLike(id)</em></p>
<p>输入作品id,返回这个作品的点赞数</p>
<p><em>GetBookmark(id)</em></p>
<p>输入作品id,返回这个作品的收藏数</p>
<p><em>GetView(id)</em></p>
<p>输入作品id,返回这个作品的浏览数</p>
<p><em>getHideFollow()</em></p>
<p>返回悄悄关注的画师id列表</p>
<p><em>getShowFollow()</em></p>
<p>返回公开关注的画师id列表</p>
<h5><span id="112-findpidpy">1.1.2 findPID.py</span></h5><p><em>findPIDs_by_Author(pid)</em></p>
<p>输入作者id,返回这个作者的全部插画id列表</p>
<p><em>findPIDs_by_Daily()</em></p>
<p>返回今日的日榜中的全部id列表</p>
<p><em>findPIDs_by_Weekly()</em></p>
<p>返回今日的周榜中的全部id列表</p>
<p><em>findPIDs_by_Monthly()</em></p>
<p>返回今日的月榜中的全部id列表</p>
<p><em>findPIDs_by_Male()</em></p>
<p>返回今日的男性日榜中的全部id列表</p>
<p><em>findPIDs_by_Female()</em></p>
<p>返回今日的女性日榜中的全部id列表</p>
<p><em>findPIDs_by_Tag()</em></p>
<p>需要输入搜索模式,tag数量以及tag,返回这个tag搜索下得到的全部作品的id列表(注:Pixiv搜索展示有上限6w张,所以时间过于久远的作品是搜不出来的)</p>
<p><em>findPIDs_by_Tag_sort()</em></p>
<p>与上一个函数类似,区别是将结果进行了排序,可以按收藏数,点赞数,浏览数排序,相当于手动解锁了按热度排序的功能,不过耗时较久.</p>
<h5><span id="113-findfollowpy">1.1.3 findFollow.py</span></h5><p><em>findFollow(mode)</em></p>
<p>输入mode,1表示公开关注的,2表示悄悄关注的,返回关注的画师id列表</p>
<h5><span id="114-mainpy">1.1.4 main.py</span></h5><p>一般情况直接运行该程序即可,会有详细的引导.</p>
<h4><span id="12-konachan">1.2 Konachan</span></h4><p><a target="_blank" rel="noopener" href="http://konachan.net/也是一个插画分享网站,直接在代码40,41行修改爬取的起始页面与终止页面.直接运行即可">http://konachan.net/也是一个插画分享网站,直接在代码40,41行修改爬取的起始页面与终止页面.直接运行即可</a>.</p>
<p>随后将两个程序部署在了vultr服务器上,主要是可以直连pixiv,利用rclone挂载上本人OneDrive,将爬下来的图片保存在OneDrive中,最终可以得到将近四百G图片.</p>
<center class="full">
<img src="/images/onedrive.png" width="60%">
</center>


<h3><span id="2人脸提取">2.人脸提取</span></h3><p>参考了这个GitHub上的项目:<a target="_blank" rel="noopener" href="https://github.com/nagadomi/lbpcascade_animeface">https://github.com/nagadomi/lbpcascade_animeface</a></p>
<p>最终提取得到2w张人脸图片,共享至OneDrive:<a target="_blank" rel="noopener" href="https://1drv.ms/u/s!AkFaXpu1Wty9k4NmlYU2rER15Au8QA?e=GxjwqY">https://1drv.ms/u/s!AkFaXpu1Wty9k4NmlYU2rER15Au8QA?e=GxjwqY</a></p>
<center class="full">
<img src="/images/face.png" width="70%">
</center>


<h3><span id="3部署环境运行代码">3.部署环境运行代码</span></h3><p>分别在两台电脑上运行了两个GitHub的项目。</p>
<h4><span id="第一台电脑上的环境部署">第一台电脑上的环境部署</span></h4><p>参考github源码：<a target="_blank" rel="noopener" href="https://github.com/NVlabs/stylegan2.git">https://github.com/NVlabs/stylegan2.git</a></p>
<p>所用计算机：Windows10  ，显卡：NVDIA GeForce GTX 1060</p>
<p>Python版本：3.6.13</p>
<p>所用到的包：见所附 requirments1.txt 文件。</p>
<p>基本步骤：安装Git，获取GitHub上的项目源码，安装2017版本的VS2017，安装CUDA和cuDNN，安装Anaconda，创建虚拟环境，修改Windows的环境变量路径，在命令行终端运行。</p>
<p><strong>1  安装git</strong>   <a target="_blank" rel="noopener" href="https://git-scm.com/downloads">https://git-scm.com/downloads</a></p>
<p><strong>2  获取源码</strong>   创建一个项目文件夹，并使用cd命令进入该文件，输入一下代码获取</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/NVlabs/stylegan2.git</span><br></pre></td></tr></table></figure>
<p><strong>3  安装VS2017</strong>  <a target="_blank" rel="noopener" href="https://docs.microsoft.com/en-us/visualstudio/releasenotes/vs2017-relnotes">https://docs.microsoft.com/en-us/visualstudio/releasenotes/vs2017-relnotes</a></p>
<p><strong>4  安装CUDA及cuDNN</strong>  </p>
<p>由于深度学习最好用到GPU参与（可以提高计算速度），而CUDA（Compute Unified Device Architecture）可以实现CPU与GPU并用的协同处理，因此需要下载。</p>
<p>限于本文参考项目源码的限制，需要下载CUDA10.0版本，下载地址为：<a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-10.0-download-archive；">https://developer.nvidia.com/cuda-10.0-download-archive；</a></p>
<p>Cudnn的下载地址为：<a target="_blank" rel="noopener" href="https://developer.nvidia.com/rdp/cudnn-archive，选择cuDNNv7.5.0">https://developer.nvidia.com/rdp/cudnn-archive，选择cuDNNv7.5.0</a>  for CUDA10.0 的windows10版本，将下载到的文件拷贝到CUDA的同名目录即可。</p>
<p><strong>5  anaconda的安装</strong> </p>
<p>anaonda包含了conda、Python等180多个科学包及其依赖项，其中的conda可以实现在同一个机器上安装不同版本的软件包及其依赖，并能够在不同的环境之间切换，非常方便，由于项目源码的年代比较久远，因此需要用conda创建python虚拟环境。</p>
<p>下载地址：<a target="_blank" rel="noopener" href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/，下载版本为：3-5.2.0-windows-x86_64.exe">https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/，下载版本为：3-5.2.0-windows-x86_64.exe</a></p>
<p><strong>6  创建虚拟环境</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda create -n your_env_name python=x.x   <span class="comment"># 使用conda创建虚拟环境</span></span><br><span class="line">activate your_env_name   <span class="comment">#激活虚拟环境</span></span><br><span class="line">pip install -r requirements.txt   <span class="comment">#根据依赖文件批量安装库，txt文件已附</span></span><br></pre></td></tr></table></figure>
<p><strong>7  修改windows的环境变量路径</strong></p>
<p>将conda、CUDA10、VS2017等加入到PATH中。</p>
<p><strong>8  运行程序</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python run_generator.py generate-images --network=gdrive:networks/stylegan2-ffhq-config-f.pkl --seeds=<span class="number">6600</span>-<span class="number">6625</span> --truncation-psi=<span class="number">0.5</span></span><br></pre></td></tr></table></figure>
<p>在./results/文件夹下可以看到结果。</p>
<h3><span id="第二台电脑上的环境部署"><strong>第二台电脑上的环境部署</strong></span></h3><p>关键是Python、PyTorch、CUDA、visual studio的版本要匹配,之前失败很多次都是版本不匹配的原因。</p>
<p>在显卡为RTX3070的电脑上部署StyleGAN项目时频繁遇到问题,发现GitHub上的很多项目都是用的TensorFlow1.x,这些版本最高只支持到CUDA10,但是RTX3070只支持CUDA11以上的版本,TensorFlow1和2的版本问题很让人头疼,于是考虑转而使用PyTorch。</p>
<p>参考github源码：<a target="_blank" rel="noopener" href="https://github.com/johnhany/stylegan2-pytorch">https://github.com/johnhany/stylegan2-pytorch</a></p>
<p>所用计算机：Windows10  ，显卡：NVDIA GeForce RTX 3070</p>
<p>Python版本：3.7.10</p>
<p>所用到的包：见所附 requirments2.txt 文件。</p>
<p>基本步骤：获取GitHub上的项目源码，安装2019版本的VS2019，安装CUDA11.1和cuDNN8.0.4，创建虚拟环境，修改Windows的环境变量路径，pip安装所需要的包，将图片放在指定路径./images/,运行:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stylegan2_pytorch --data ./images/ --num_workers=0</span><br></pre></td></tr></table></figure>
<p>随后在./results/文件夹下可以看到结果。</p>
<p><strong>关于运行结果分别见result1  和result2文件夹。</strong></p>
<h2><span id="四-结果展示">四 结果展示</span></h2><p>最终生成的图像选取一部分如下，有些已经可以达到以假乱真的效果了</p>
<center class="half">
<img src="/images/gan1.jpg" width="60%"> <img src="/images/gan2.jpg" width="60%"> 
</center>


<h2><span id="五-关于gan的进一步讨论">五 关于GAN的进一步讨论</span></h2><h3><span id="gan优点">GAN优点</span></h3><p>GAN的核心思想是基于通过鉴别器进行的“间接”训练，而这种训练本身也是动态更新的这基本上意味着生成器没有被训练去最小化到特定图像的距离，而是欺骗鉴别器，这使得模型能够以无监督的方式学习，GAN是隐式生成模型，这意味着它们不显式地建模似然函数。<br>虽然GAN最初是作为一种无监督学习的生成模型提出的，但事实证明，GAN也适用于半监督学习、完全监督学习、和强化学习。<br>能更好建模数据分布（图像更锐利、清晰）。<br>理论上，GANs 能训练任何一种生成器网络。其他的框架需要生成器网络有一些特定的函数形式，比如输出层是高斯的。</p>
<h3><span id="gan缺点">GAN缺点</span></h3><p>无需利用马尔科夫链反复采样，无需在学习过程中进行推断，没有复杂的变分下界，避开近似计算棘手的概率的难题。<br>难训练，不稳定。生成器和判别器之间需要很好的同步，但是在实际训练中很容易D收敛，G发散。D/G 的训练需要精心的设计。<br>模式缺失（Mode Collapse）问题。GANs的学习过程可能出现模式缺失，生成器开始退化，总是生成同样的样本点，无法继续学习。</p>
<h3><span id="gan应用">GAN应用</span></h3><ol>
<li><p>GAN可以用来生成艺术图像，GAN还可以用来修复照片，或者为想象中的时装模特创作照片；</p>
</li>
<li><p>GAN可以用来生成天文学图像，模拟暗物质研究中的引力透镜效应；</p>
</li>
<li><p>GAN是一种通过高能物理实验的量热计快速准确地模拟高能射流形成和簇射的方法；</p>
</li>
<li><p>在电子游戏领域，GAN根据低分辨率的2D图像训练生成高分辨率的4k图像，然后根据原始图像1的分辨率进行采样，可以使原始图像更加清晰，获得更加清晰的纹理，同时不丢失原始图像的色彩、细节。</p>
</li>
<li><p>在迁移学习方面，最先进的迁移学习研究使用GAN来加强潜在特征空间的对齐，例如在深度强化学习中。</p>
</li>
<li><p>其它应用，gan可以从图像、和视频中的运动模型模式中重建物体的三维模型，可用于显示人的外表随着年龄的变化；一种GAN模型——Speech2Face可以通过人的声音重建其外貌；GAN也可处理时间序列的数据，例如，recurrent GANs  可以生成能量数据用于机器学习。</p>
</li>
</ol>
<h3><span id="gan引起的担忧危害">GAN引起的担忧（危害）</span></h3><p>可能会将GAN用于可能会导致犯罪的照片和视频，创建虚假的个人资料，使用图像合成技术生成涩情视频等，具有极大的潜在危害。</p>
<h2><span id="六-关于本项目的总结">六 关于本项目的总结</span></h2><p>本文使用style生成基于从Pixiv网站爬取的二次元图像，然后截取图像中的脸部图像，经过Style-GAN生成新的二次元图像。与根据大量真实人脸的照片生成并不存在的人脸照片类似，通过多次训练，完全可以达到以假乱真的效果，只不过由于设备原因（gpu性能不高只使用了单个gpu），代码运行时间过长，可以预计未来数据量提升，必然会带动计算能力的提升，二者形成正循环，同时也意味着人类的隐私会越来越少，人脸、声音等信息都会被作为数据进行存储。</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>Image Generator: Application and Implementation of StyleGAN</p><p><a href="http://example.com/2021/08/28/Image-Generator-Application-and-Implementation-of-StyleGAN/">http://example.com/2021/08/28/Image-Generator-Application-and-Implementation-of-StyleGAN/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Yuzi Liang</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2021-08-28</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2023-09-25</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Machine-Learning/">Machine Learning</a><a class="link-muted mr-2" rel="tag" href="/tags/Web-Crawler/">Web Crawler</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2021/09/17/Totorial-of-Google-Colab-and-Pytorch/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Tutorial of Google Colab and PyTorch</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2021/08/07/Notes-of-Machine-Learning-P22/"><span class="level-item">Notes of Machine Learning(P22-P23)</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'http://example.com/2021/08/28/Image-Generator-Application-and-Implementation-of-StyleGAN/';
            this.page.identifier = '2021/08/28/Image-Generator-Application-and-Implementation-of-StyleGAN/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'lyz' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1 is-sticky"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-04-11T22:35:16.000Z">2023-04-11</time></p><p class="title"><a href="/2023/04/11/CNN-with-Pytorch/">CNN with Pytorch</a></p><p class="categories"><a href="/categories/Learning-Notes/">Learning Notes</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-04-04T04:22:22.000Z">2023-04-03</time></p><p class="title"><a href="/2023/04/03/Diffusion-model/">Diffusion model</a></p><p class="categories"><a href="/categories/Learning-Notes/">Learning Notes</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-11-08T02:10:30.000Z">2022-11-07</time></p><p class="title"><a href="/2022/11/07/TensorFlow-Tutorial/">TensorFlow Tutorial</a></p><p class="categories"><a href="/categories/Learning-Notes/">Learning Notes</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-05-28T22:58:52.000Z">2022-05-28</time></p><p class="title"><a href="/2022/05/28/Lattice-Boltzmann-Method/">Lattice Boltzmann Method</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-09-18T01:47:06.000Z">2021-09-17</time></p><p class="title"><a href="/2021/09/17/Totorial-of-Google-Colab-and-Pytorch/">Tutorial of Google Colab and PyTorch</a></p><p class="categories"><a href="/categories/Learning-Notes/">Learning Notes</a></p></div></article></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Demo/"><span class="level-start"><span class="level-item">Demo</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Learning-Notes/"><span class="level-start"><span class="level-item">Learning Notes</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/Project-Summary/"><span class="level-start"><span class="level-item">Project Summary</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Machine-Learning/"><span class="tag">Machine Learning</span><span class="tag">13</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Magnetics/"><span class="tag">Magnetics</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Monte-Carlo-Method/"><span class="tag">Monte Carlo Method</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PyTorch/"><span class="tag">PyTorch</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Selenium/"><span class="tag">Selenium</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TensorFlow/"><span class="tag">TensorFlow</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Thermoelectricity/"><span class="tag">Thermoelectricity</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Web-Crawler/"><span class="tag">Web Crawler</span><span class="tag">2</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/ustc_logo.jpg" alt="Yuzi Liang | University of Science and Technology of China" height="28"></a><p class="is-size-7"><span>&copy; 2023 Yuzi Liang</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/mhchem.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>